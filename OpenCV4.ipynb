{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV notebook - ©Arkaprabha Majumdar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1. Importing, Displaying and Grayscaling images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread( #reads images\n",
    "    '~/Desktop/Deep_Learning_Udemy/img/40-Of-The-Most-Amazing-Humans-Met-On-The-Streets-By-The-humans-Of-Movement-Worldwide4__700.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',image[:,:,1]) #shows the image in a separate window - sometimes Kernel crashes\n",
    "cv2.waitKey(0)#essential with imshow\n",
    "cv2.destroyAllWindows() #also essential - without which kernel will hang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('grayscale image',gray_image) #shows the image in a separate window - sometimes Kernel crashes\n",
    "cv2.waitKey(0)#essential with imshow\n",
    "cv2.destroyAllWindows() #also essential - without which kernel will hang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brilliant ! Done. It opens in a separate window.\n",
    "Remember to always exit that window by \"Esc\" key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0,0] #This is the B,G,R values of the first pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[45,45] #This is the B,G,R values of the 45,45 pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image[0,0] #outputs a single value of grayscale for 0,0 pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_image=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('HSV image',hsv_image) #shows the image in a separate window - sometimes Kernel crashes\n",
    "cv2.waitKey(0)#essential with imshow\n",
    "cv2.destroyAllWindows() #also essential - without which kernel will hang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('HSV image hue only',hsv_image[:,:,0]) #shows the image in a separate window - sometimes Kernel crashes\n",
    "cv2.waitKey(0)#essential with imshow\n",
    "cv2.destroyAllWindows() #also essential - without which kernel will hang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a process as above, we can output each of the HUE, SATURATION and VALUE channels\n",
    "as separate images...this is nothing particularly useful, but an explanatory tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image[:,:,0] does not however work on the BGR image.\n",
    "### \"0\" instead refers to grayscale, \"1\" refers to transparency channels, etc...\n",
    "### The kernel hangs when trying out arguments except 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead we use the \"split\" function\n",
    "B,G,R = cv2.split(image)\n",
    "B\n",
    "cv2.imshow('green',G) #shows the image in a separate window - sometimes Kernel crashes\n",
    "cv2.waitKey(0)#essential with imshow\n",
    "cv2.destroyAllWindows() #also essential - without which kernel will hang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But these above images are NOTHING like what I wanted.\n",
    "#### I expected RGB filters on my image... well here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros=np.zeros(image.shape[:2],dtype='uint8')\n",
    "cv2.imshow(\"Red filter\",cv2.merge([zeros,zeros,R]))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recreate a whole image, we need the whole RGB matrix\n",
    "So we assign the whole matrix for B,G as zeros to create a red filter\n",
    "...and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can create histograms of the BGR channels too !\n",
    "#### We use the cv2.calcHist along with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color = ['b','g','r']\n",
    "\n",
    "#the enumerate is a built in function which gives you tuples of (index,list_element)\n",
    "for i,col in enumerate(color):\n",
    "    hist=cv2.calcHist([image],[i],None,[256],[0,256])\n",
    "    plt.plot(hist,color=col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calcHist function has 5 arguments:\n",
    "1. [image] (even though it is already a matrix, we need to give another square brackets)\n",
    "2. channel:\n",
    "            [0] = blue (for color images) / grayscale (for grayscale images)\n",
    "            [1] = green\n",
    "            [2] = red\n",
    "3. mask: we can either create a mask/selection of the image (later),\n",
    "        or the value \"None\" gives us the full scale image\n",
    "4. bin size: this is the bin size of the histogram. \n",
    "            [256] = full scale\n",
    "5. range: generally [0,256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2. Drawing images and shapes using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So you want to create rectangles and squares around faces in deep Learning\n",
    "#### but we may need to make other shapes for better optimization or fun..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black squares and lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch1 = np.zeros((512,512,3),np.uint8) #To create a zero 3-D matrix\n",
    "cv2.imshow('Black square',sketch1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try to draw a generic straight line between two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch2 = np.zeros((512,512,3),np.uint8) #To create a zero 3-D matrix\n",
    "cv2.line(sketch2,(0,0),(511,511),(255,255,255),5)\n",
    "cv2.imshow('Black square',sketch2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to do a drawing of a house\n",
    "sketch3 = np.zeros((512,512,3),np.uint8) #To create a zero 3-D matrix\n",
    "\n",
    "cv2.line(sketch3,(100,200),(300,200),(255,255,255),5)\n",
    "cv2.line(sketch3,(100,200),(220,100),(255,255,255),5)\n",
    "cv2.line(sketch3,(150,200),(150,300),(255,255,255),5)\n",
    "cv2.line(sketch3,(150,300),(250,300),(255,255,255),5)\n",
    "cv2.line(sketch3,(250,300),(250,200),(255,255,255),5)\n",
    "cv2.line(sketch3,(220,100),(300,200),(255,255,255),5)\n",
    "cv2.imshow('Black square',sketch3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we make a circle\n",
    "sketch4 = np.zeros((512,512,3),np.uint8) #To create a zero 3-D matrix\n",
    "\n",
    "#arguments are: image, center,radius,color,thickness\n",
    "cv2.circle(sketch4,(267,267),100,(0,0,200),3)\n",
    "cv2.imshow(\"red circle\",sketch4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create polygons, we need to first make a matrix of points\n",
    "points = np.array([[10, 410], [26, 32], [366, 88], [45, 85]])\n",
    "\n",
    "sketch5 = np.zeros((512,512,3),np.uint8) #To create a zero 3-D matrix\n",
    "\n",
    "#\"True\" stands for closed polygon or not\n",
    "cv2.polylines(sketch5, [points], 1, (255,255,255))\n",
    "cv2.imshow(\"rpolygon\",sketch5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we can also add text to our images\n",
    "cv2.putText(sketch5,\"YO\",(200,250),cv2.FONT_HERSHEY_DUPLEX,2,(0,0,245),2)\n",
    "cv2.imshow(\"rpolygon\",sketch5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just need to have a good sense of the coordinates on your image ! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #3. Affine and Non Affine Transformations\n",
    "\n",
    "## Translation - Affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine transformation preserve the structure of an image but non affine dont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x,y) -> (x+m,y+n)\n",
    "h,w = image.shape[:2] #height and width\n",
    "\n",
    "T=np.float32([[1,0,h/4],[0,1,w/4]])\n",
    "\n",
    "'''This is the transformation matrix:   [1  0  m]\n",
    "                                        [0  1  n]'''\n",
    "\n",
    "\n",
    "translated_img=cv2.warpAffine(image,T,(w,h))\n",
    "cv2.imshow(\"Translated by 1/4\",translated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Some of the image is cut off, due to the last argument of (w,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation - Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x,y) -> (x+m,y+n)\n",
    "h,w = image.shape[:2] #height and width\n",
    "\n",
    "'''A rotation matrix created by cv2.getRotationMatrix2D:    [cosθ  -sinθ]\n",
    "                                                        [sinθ   cosθ]'''\n",
    "\n",
    "\n",
    "rotation_matrix=cv2.getRotationMatrix2D((w/2,h/2),45,1)\n",
    "\n",
    "'''The arguments of the function are:\n",
    "                    rotation_center(x,y)\n",
    "                    angle of rotation\n",
    "                    scale ((0,1) gives smaller image]\n",
    "                           (1,∞) gives larger image)'''\n",
    "rotated_img=cv2.warpAffine(image,rotation_matrix,(w,h))\n",
    "cv2.imshow(\"Rotated by 45°\",rotated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Some of the image is cut off, due to the last argument of (w,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to turn it 90°, then it is better to do:\n",
    "####    rotated_image=cv2.transpose(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing & Interpolation - Affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While upscaling images, there is a need for interpolation to fill the gaps\n",
    "between the pixels of the low res image.\n",
    "(used in GPS also)\n",
    "https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_scaled_by_fourth=cv2.resize(image,None,fx=0.25,fy=0.25)\n",
    "\n",
    "# arguments are: (image, dimensions of output(width,height), x_scale, y_scale)\n",
    "\n",
    "cv2.imshow(\"Image made smaller to 1/4 size\",image_scaled_by_fourth)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To scale it up, we can use any of these 5 interpolation techniques:\n",
    "            1. INTER_AREA \n",
    "            2. INTER_NEAREST\n",
    "            3. INTER_LINEAR\n",
    "            4. INTER_CUBIC\n",
    "            5. INTER_LANCZOS4'''\n",
    "image_zoom_2 = cv2.resize(image,None,fx=3,fy=3,interpolation=cv2.INTER_LANCZOS4)\n",
    "# arguments are: (image, dimensions of output(width,height), x_scale, y_scale, interpolation)\n",
    "\n",
    "cv2.imshow(\"Image made double\",image_zoom_2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyramid scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method to quickly scale images is using the inbuilt pyramid functions:\n",
    "    pyrDown\n",
    "    pyrUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller=cv2.pyrDown(image)\n",
    "cv2.imshow(\"half\",smaller)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    smaller=cv2.pyrDown(smaller)\n",
    "cv2.imshow(\"half\",smaller)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "larger=cv2.pyrUp(smaller)\n",
    "for i in range(3):\n",
    "    larger=cv2.pyrUp(larger)\n",
    "cv2.imshow(\"rescaled\",larger)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop\n",
    "There is no inbuilt function to crop images.\n",
    "BUT we can use numpy slicing on the image matrix !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = image.shape[:2]\n",
    "cropped = image[int(h*.25):int(h*.75),int(w*.25):int(w*.75)]\n",
    "cv2.imshow(\"rescaled\",cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brighten/Darken images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=np.ones(image.shape,\"uint8\")\n",
    "added=cv2.add(image,M*25)\n",
    "subtracted=cv2.subtract(image,M*25)\n",
    "cv2.imshow(\"bright\",added)\n",
    "cv2.imshow(\"dark\",subtracted)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blurring using kernels - convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_3x3=np.ones((3,3),np.float32)/9 #9 is for normalization\n",
    "blurred=cv2.filter2D(image,-1,kernel_3x3)\n",
    "cv2.imshow(\"filter2D\",blurred)\n",
    "\n",
    "#other methods are:\n",
    "box_blur=cv2.blur(image,(3,3))\n",
    "gaussian=cv2.GaussianBlur(image,(3,3),0)\n",
    "median=cv2.medianBlur(image,5) #5 is the median\n",
    "\n",
    "#and the most effective for removing noise:\n",
    "bilateral=cv2.bilateralFilter(image,3,50,50)\n",
    "'''arguments are:\n",
    "        d: diameter of color pixel neighbourhood\n",
    "        sigmacolor: value of sigma in color space (more value = colors farther to each other will mix)\n",
    "        sigmacoord: value of sigma in coordinate system(more value = pixels farther to each other will mix -\n",
    "                            given they lie in sigmacolor range)'''\n",
    "\n",
    "cv2.imshow(\"box_blur\",box_blur)\n",
    "cv2.imshow(\"gaussian_blur\",gaussian)\n",
    "cv2.imshow(\"median_blur\",median)\n",
    "cv2.imshow(\"bilateral blur\",bilateral)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding/ Binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding is the process of converting a grayscale image into binary form.\n",
    "dark areas -> 0\n",
    "light areas -> 255\n",
    "\n",
    "It is a good practice to blur images before thresholding to remove noise.\n",
    "Types of thresholds are all given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gray=cv2.imread( #reads grayscale_image\n",
    "    '~/Desktop/Deep_Learning_Udemy/img/humans.jpg',0)\n",
    "_,th_binary=cv2.threshold(image_gray,127,255,cv2.THRESH_BINARY)\n",
    "_,th_binary_inv=cv2.threshold(image_gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "_,th_trunc=cv2.threshold(image_gray,127,255,cv2.THRESH_TRUNC)\n",
    "_,th_tozero=cv2.threshold(image_gray,127,255,cv2.THRESH_TOZERO)\n",
    "blur=cv2.GaussianBlur(image_gray,(3,3),0)\n",
    "_,th_otsu=cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "cv2.imshow(\"BINARY\",th_binary)\n",
    "cv2.imshow(\"BIN_INV\",th_binary_inv)\n",
    "cv2.imshow(\"TRUNC\",th_trunc)\n",
    "cv2.imshow(\"TOZERO\",th_tozero)\n",
    "cv2.imshow(\"OTSU\",th_otsu) #otsu is infact an adaptive thresholding algorithm\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
